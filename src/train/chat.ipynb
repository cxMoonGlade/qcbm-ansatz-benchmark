{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e10dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmdagg_prob.py\n",
    "# ======================================================\n",
    "#  MMDAgg on probability vectors (discrete distributions)\n",
    "#  - 支持多核 + 多带宽 + 权重聚合\n",
    "#  - 纯 JAX，可 jit 到 GPU / TPU\n",
    "# ======================================================\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# ==============================================\n",
    "#  mmdagg_probs.py  ―  Prob‑vector MMDAgg (JAX)\n",
    "#  kernels: laplace / gaussian / imq / matern ν∈{0.5,1.5,2.5}\n",
    "# ==============================================\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "# ---------- 0) 常量映射 ----------\n",
    "_KID = dict(laplace=0, gaussian=1, imq=2,\n",
    "            matern05=3, matern15=4, matern25=5)\n",
    "_IDK = {v: k for k, v in _KID.items()}\n",
    "_MID = {\"l1\": 0, \"l2\": 1}                        # metric id\n",
    "\n",
    "\n",
    "# ---------- 1) 距离矩阵（一次性构好） ----------\n",
    "def _make_dist(d: int, dtype=jnp.float32):\n",
    "    eye  = jnp.eye(d, dtype=dtype)\n",
    "    off  = 1.0 - eye\n",
    "    D_l1 = off * 2.0\n",
    "    D_l2 = off * jnp.sqrt(2.0)\n",
    "    return D_l1, D_l2\n",
    "\n",
    "\n",
    "# ---------- 2) 单核矩阵 ----------\n",
    "def _kernel_matrix(dist, k_id: int, bw):\n",
    "    r = dist / bw\n",
    "\n",
    "    def matern(nu):\n",
    "        if nu == 0.5:\n",
    "            return jnp.exp(-r)\n",
    "        if nu == 1.5:\n",
    "            return (1 + jnp.sqrt(3)*r) * jnp.exp(-jnp.sqrt(3)*r)\n",
    "        if nu == 2.5:\n",
    "            return (1 + jnp.sqrt(5)*r + 5*r**2/3) * jnp.exp(-jnp.sqrt(5)*r)\n",
    "\n",
    "    return jax.lax.switch(\n",
    "        k_id,\n",
    "        [\n",
    "            lambda: jnp.exp(-r),            # laplace  (L1)\n",
    "            lambda: jnp.exp(-r**2),         # gaussian (L2)\n",
    "            lambda: (1 + r**2)**-0.5,       # imq      (L2)\n",
    "            lambda: matern(0.5),\n",
    "            lambda: matern(1.5),\n",
    "            lambda: matern(2.5),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------- 3) JIT 数值核心 ----------\n",
    "def _build_core(D_l1, D_l2):\n",
    "    \"\"\"闭包捕获距离矩阵 → 避免当作 JIT 参数传入\"\"\"\n",
    "    @jax.jit\n",
    "    def _core(delta, k_ids, m_ids, bws):\n",
    "        \"\"\"返回 (T,) MMD 值\"\"\"\n",
    "        def body(i, acc):\n",
    "            dist = jax.lax.select(m_ids[i] == 0, D_l1, D_l2)\n",
    "            K    = _kernel_matrix(dist, k_ids[i], bws[i])\n",
    "            acc  = acc.at[i].set(delta @ K @ delta)\n",
    "            return acc\n",
    "\n",
    "        m_init = jnp.zeros_like(bws)\n",
    "        return jax.lax.fori_loop(0, bws.size, body, m_init)\n",
    "\n",
    "    return _core\n",
    "\n",
    "\n",
    "# ---------- 4) 权重 ----------\n",
    "def _create_weights(N: int, mode: str = \"uniform\") -> jnp.ndarray:\n",
    "    w = jnp.ones(N)\n",
    "    if mode == \"decreasing\":\n",
    "        w = 1.0 / jnp.arange(1, N + 1)\n",
    "    elif mode == \"increasing\":\n",
    "        w = 1.0 / jnp.arange(N, 0, -1)\n",
    "    elif mode == \"centred\":\n",
    "        idx = jnp.arange(N)\n",
    "        mid = (N - 1) / 2\n",
    "        w = 1.0 / (jnp.abs(idx - mid) + 1)\n",
    "    return w / w.sum()\n",
    "\n",
    "\n",
    "# ---------- 5) kernel / metric 序列 ----------\n",
    "def _ids_for_kernel(flag: str, n_bw: int):\n",
    "    def seq(kname, metric):\n",
    "        k = _KID[kname]; m = _MID[metric]\n",
    "        return [k] * n_bw, [m] * n_bw\n",
    "\n",
    "    if flag == \"laplace_gaussian\":\n",
    "        k1, m1 = seq(\"laplace\",  \"l1\")\n",
    "        k2, m2 = seq(\"gaussian\", \"l2\")\n",
    "        return k1 + k2, m1 + m2\n",
    "\n",
    "    if flag == \"gaussian_laplace\":\n",
    "        k1, m1 = seq(\"gaussian\", \"l2\")\n",
    "        k2, m2 = seq(\"laplace\",  \"l1\")\n",
    "        return k1 + k2, m1 + m2\n",
    "\n",
    "    if flag == \"all\":\n",
    "        names = [\n",
    "            (\"laplace\",   \"l1\"),\n",
    "            (\"gaussian\",  \"l2\"),\n",
    "            (\"imq\",       \"l2\"),\n",
    "            (\"matern05\",  \"l1\"), (\"matern15\", \"l1\"), (\"matern25\", \"l1\"),\n",
    "            (\"matern05\",  \"l2\"), (\"matern15\", \"l2\"), (\"matern25\", \"l2\"),\n",
    "        ]\n",
    "        k_ids, m_ids = [], []\n",
    "        for kname, metric in names:\n",
    "            k_vec, m_vec = seq(kname, metric)\n",
    "            k_ids += k_vec\n",
    "            m_ids += m_vec\n",
    "        return k_ids, m_ids\n",
    "\n",
    "    raise ValueError(f\"Unknown kernel flag '{flag}'\")\n",
    "\n",
    "\n",
    "# ---------- 6) 公开 API ----------\n",
    "def mmdagg_prob(\n",
    "    p, q,\n",
    "    *,\n",
    "    kernel=\"laplace_gaussian\",\n",
    "    number_bandwidths=10,\n",
    "    base_bw=1.0,\n",
    "    ratio=2.0,\n",
    "    weights_type=\"uniform\",\n",
    "    build_details: bool = True,\n",
    "    dtype=jnp.float32,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    p, q   : (d,) 概率向量 (sum=1)\n",
    "    kernel : 'laplace_gaussian' | 'gaussian_laplace' | 'all'\n",
    "    number_bandwidths : 每核带宽数\n",
    "    base_bw, ratio    : 带宽 λ₀·ratioᵏ\n",
    "    weights_type      : uniform / decreasing / increasing / centred\n",
    "    build_details     : False → 仅返回标量 loss（训练时用）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss            : jnp.float32 scalar\n",
    "    details (opt.)  : dict（人类可读）\n",
    "    \"\"\"\n",
    "    p = jnp.asarray(p, dtype=dtype)\n",
    "    q = jnp.asarray(q, dtype=dtype)\n",
    "    assert p.shape == q.shape and p.ndim == 1, \"p,q shape mismatch\"\n",
    "    d      = p.size\n",
    "    delta  = p - q\n",
    "\n",
    "    # ---- 预计算距离矩阵 ----\n",
    "    D_l1, D_l2 = _make_dist(d, dtype)\n",
    "    _core      = _build_core(D_l1, D_l2)\n",
    "\n",
    "    # ---- 带宽向量 ----\n",
    "    bw_seq = base_bw * ratio ** jnp.arange(number_bandwidths, dtype=dtype)\n",
    "\n",
    "    # ---- kernel / metric id ----\n",
    "    k_ids_l, m_ids_l = _ids_for_kernel(kernel, number_bandwidths)\n",
    "    k_ids = jnp.array(k_ids_l, dtype=jnp.int32)\n",
    "    m_ids = jnp.array(m_ids_l, dtype=jnp.int32)\n",
    "    bws   = jnp.tile(bw_seq, k_ids.size // number_bandwidths)\n",
    "\n",
    "    # ---- 数值核心 ----\n",
    "    mmd_vals = _core(delta, k_ids, m_ids, bws)          # (T,)\n",
    "\n",
    "    # ---- 权重聚合 ----\n",
    "    B = number_bandwidths           # 每核带宽数（静态）\n",
    "    K = len(k_ids_l) // B           # 核数\n",
    "    w_bw   = _create_weights(B, weights_type)           # (B,)\n",
    "    weights = jnp.tile(w_bw, K) / K                     # (T,)\n",
    "    loss    = jnp.sum(weights * mmd_vals)\n",
    "\n",
    "    if not build_details:\n",
    "        return loss                                     # <<< 训练路径\n",
    "\n",
    "    # ---- details dict (Python，非 JIT) ----\n",
    "    details = {}\n",
    "    for i in range(bws.size):\n",
    "        details[f\"Single test {i+1}\"] = {\n",
    "            \"Kernel\":   _IDK[int(k_ids_l[i])],\n",
    "            \"Metric\":   \"l1\" if m_ids_l[i] == _MID[\"l1\"] else \"l2\",\n",
    "            \"Bandwidth\": float(bws[i]),\n",
    "            \"Weight\":    float(weights[i]),\n",
    "            \"MMD\":       float(mmd_vals[i]),\n",
    "        }\n",
    "\n",
    "    return loss, details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5192a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: gpu\n",
      "tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import jax, jax.numpy as jnp\n",
    "from jax.experimental import host_callback as hcb\n",
    "\n",
    "def f(x):\n",
    "    # 打印当前设备\n",
    "    hcb.id_print(jax.devices()[0])\n",
    "    return jnp.sin(x).sum()\n",
    "\n",
    "x = jnp.ones((10, 10))\n",
    "print(\"tensor device:\", x.device())     # 应该是 cuda:0\n",
    "\n",
    "# JIT 后再看\n",
    "y = jax.jit(f)(x)                       # 首次会编译\n",
    "print(\"result:\", y)\n",
    "\n",
    "# ----------------------------------------\n",
    "import jax, jax.numpy as jnp\n",
    "x = jnp.ones(())                 # 随便一块张量\n",
    "print(\"backend:\", jax.default_backend())\n",
    "\n",
    "# 新版：\n",
    "print(\"tensor device:\", x.device)          # 推荐\n",
    "# 兼容老版：\n",
    "try:\n",
    "    print(\"tensor device (method):\", x.device())  # 如果是属性就会报 TypeError\n",
    "except TypeError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867c9810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated loss: 0.006387514190464572\n",
      "('Single test 1', {'Kernel': 'laplace', 'Metric': 'l1', 'Bandwidth': 1.0, 'Weight': 0.09375, 'MMD': 0.012969970703125})\n"
     ]
    }
   ],
   "source": [
    "# ---- 单次测试 ----\n",
    "p = jnp.array([0.15,0.1,0.05,0.1,0.25,0.1,0.15,0.1])\n",
    "q = jnp.array([0.2 ,0.05,0.1,0.05,0.25,0.05,0.2,0.1])\n",
    "\n",
    "loss, info = mmdagg_prob(\n",
    "    p, q,\n",
    "    kernel=\"laplace_gaussian\",\n",
    "    number_bandwidths=4,\n",
    "    weights_type=\"centred\",\n",
    ")\n",
    "print(\"Aggregated loss:\", float(loss))\n",
    "print(next(iter(info.items())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f50ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m Y = categorical_sample(p_fake, subkey, \u001b[32m1000\u001b[39m)  \u001b[38;5;66;03m# shape (1000, 8)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 调用mmdagg，注意 kernel=\"laplace_gaussian\" 是你的主流程\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m results = \u001b[43mmmdagg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dictionary\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- MMD stats for each kernel/bandwidth ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 1. 提取MMD和权重，并打印核信息\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/pjit.py:340\u001b[39m, in \u001b[36m_cpp_pjit.<locals>.cache_miss\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.no_tracing.value:\n\u001b[32m    336\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info.fun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    337\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m`jit`, but \u001b[39m\u001b[33m'\u001b[39m\u001b[33mno_tracing\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    339\u001b[39m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m  pgle_profiler) = \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m maybe_fastpath_data = _get_fastpath_data(\n\u001b[32m    343\u001b[39m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr.effects,\n\u001b[32m    344\u001b[39m     jaxpr.consts, jit_info.abstracted_axes,\n\u001b[32m    345\u001b[39m     pgle_profiler)\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/pjit.py:191\u001b[39m, in \u001b[36m_python_pjit_helper\u001b[39m\u001b[34m(fun, jit_info, *args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m   args_flat = \u001b[38;5;28mmap\u001b[39m(core.full_lower, args_flat)\n\u001b[32m    190\u001b[39m   core.check_eval_args(args_flat)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m   out_flat, compiled, profiler = \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    193\u001b[39m   out_flat = pjit_p.bind(*args_flat, **p.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/pjit.py:1809\u001b[39m, in \u001b[36m_pjit_call_impl_python\u001b[39m\u001b[34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, donated_invars, ctx_mesh, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[39m\n\u001b[32m   1797\u001b[39m compiler_options_kvs = compiler_options_kvs + \u001b[38;5;28mtuple\u001b[39m(pgle_compile_options.items())\n\u001b[32m   1798\u001b[39m \u001b[38;5;66;03m# Passing mutable PGLE profile here since it should be extracted by JAXPR to\u001b[39;00m\n\u001b[32m   1799\u001b[39m \u001b[38;5;66;03m# initialize the fdo_profile compile option.\u001b[39;00m\n\u001b[32m   1800\u001b[39m compiled = \u001b[43m_resolve_and_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[43m=\u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platforms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1809\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1811\u001b[39m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n\u001b[32m   1812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compiled._auto_spmd_lowering \u001b[38;5;129;01mand\u001b[39;00m config.enable_checks.value:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2462\u001b[39m, in \u001b[36mMeshComputation.compile\u001b[39m\u001b[34m(self, compiler_options)\u001b[39m\n\u001b[32m   2460\u001b[39m compiler_options_kvs = \u001b[38;5;28mself\u001b[39m._compiler_options_kvs + t_compiler_options\n\u001b[32m   2461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options_kvs:\n\u001b[32m-> \u001b[39m\u001b[32m2462\u001b[39m   executable = \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2465\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compiler_options_kvs:\n\u001b[32m   2466\u001b[39m     \u001b[38;5;28mself\u001b[39m._executable = executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:3004\u001b[39m, in \u001b[36mUnloadedMeshExecutable.from_hlo\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3001\u001b[39m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   3003\u001b[39m util.test_event(\u001b[33m\"\u001b[39m\u001b[33mpxla_cached_compilation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3004\u001b[39m xla_executable = \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3010\u001b[39m orig_out_shardings = out_shardings\n\u001b[32m   3012\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2795\u001b[39m, in \u001b[36m_cached_compilation\u001b[39m\u001b[34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[39m\n\u001b[32m   2787\u001b[39m compile_options = create_compile_options(\n\u001b[32m   2788\u001b[39m     computation, mesh, spmd_lowering, tuple_args, auto_spmd_lowering,\n\u001b[32m   2789\u001b[39m     allow_prop_to_inputs, allow_prop_to_outputs, backend,\n\u001b[32m   2790\u001b[39m     dev, pmap_nreps, compiler_options)\n\u001b[32m   2792\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dispatch.log_elapsed_time(\n\u001b[32m   2793\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{elapsed_time:.9f}\u001b[39;00m\u001b[33m sec\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2794\u001b[39m     fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[32m-> \u001b[39m\u001b[32m2795\u001b[39m   xla_executable = \u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2796\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2797\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2798\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/compiler.py:432\u001b[39m, in \u001b[36mcompile_or_get_cached\u001b[39m\u001b[34m(backend, computation, devices, compile_options, host_callbacks, pgle_profiler)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    431\u001b[39m   log_persistent_cache_miss(module_name, cache_key)\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_and_write_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/compiler.py:694\u001b[39m, in \u001b[36m_compile_and_write_cache\u001b[39m\u001b[34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_and_write_cache\u001b[39m(\n\u001b[32m    686\u001b[39m     backend: xc.Client,\n\u001b[32m    687\u001b[39m     computation: ir.Module,\n\u001b[32m   (...)\u001b[39m\u001b[32m    691\u001b[39m     cache_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    692\u001b[39m ) -> xc.LoadedExecutable:\n\u001b[32m    693\u001b[39m   start_time = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m   executable = \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m   compile_time = time.monotonic() - start_time\n\u001b[32m    698\u001b[39m   _cache_write(\n\u001b[32m    699\u001b[39m       cache_key, compile_time, module_name, backend, executable, host_callbacks\n\u001b[32m    700\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/profiler.py:334\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    333\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gg/lib/python3.12/site-packages/jax/_src/compiler.py:324\u001b[39m, in \u001b[36mbackend_compile\u001b[39m\u001b[34m(backend, module, options, host_callbacks)\u001b[39m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.compile(\n\u001b[32m    319\u001b[39m         built_c, compile_options=options, host_callbacks=host_callbacks\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[32m    322\u001b[39m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[32m    323\u001b[39m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m xc.XlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    326\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m error_handler \u001b[38;5;129;01min\u001b[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# from mmdagg import *\n",
    "\n",
    "# def categorical_sample(probs, key, num_samples):\n",
    "#     # probs: (d,)  - 概率向量\n",
    "#     # 返回: (num_samples, d) - one-hot采样\n",
    "#     idxs = jax.random.choice(key, len(probs), shape=(num_samples,), p=probs)\n",
    "#     return jnp.eye(len(probs))[idxs]\n",
    "\n",
    "# d= 8\n",
    "# p_true = jnp.array([0.15,0.1,0.05,0.1,0.25,0.1,0.15,0.1])\n",
    "# p_fake = jnp.array([0.20,0.05,0.10,0.05,0.25,0.05,0.20,0.10])\n",
    "\n",
    "# # 从这两个分布各采1000个样本\n",
    "# key = jax.random.PRNGKey(42)\n",
    "# X = categorical_sample(p_true, key, 1000)  # shape (1000, 8)\n",
    "# key, subkey = jax.random.split(key)\n",
    "# Y = categorical_sample(p_fake, subkey, 1000)  # shape (1000, 8)\n",
    "\n",
    "# # 调用mmdagg，注意 kernel=\"laplace_gaussian\" 是你的主流程\n",
    "# results = mmdagg(X, Y, return_dictionary=True)\n",
    "# print(\"--- MMD stats for each kernel/bandwidth ---\")\n",
    "\n",
    "# # 1. 提取MMD和权重，并打印核信息\n",
    "# mmd_values = []\n",
    "# kernel_names = []\n",
    "# for k, v in results.items():\n",
    "#     if k.startswith(\"Single test\"):\n",
    "#         kernel_name = [key for key in v if key.startswith(\"Kernel\")][0]\n",
    "#         kernel_names.append(kernel_name)\n",
    "#         print(f\"{k}:  {kernel_name},  bw={v['Bandwidth']:.3f},  MMD={v['MMD']:.6f}\")\n",
    "#         mmd_values.append(v[\"MMD\"])\n",
    "# mmd_values = jnp.array(mmd_values)\n",
    "\n",
    "\n",
    "# # 2. 构造权重（权重分配方式与mmdagg主流程保持一致！）\n",
    "# number_kernels = len(set(kernel_names))  # 例如 laplace, gaussian 就是2\n",
    "# number_bandwidths = len(mmd_values) // number_kernels\n",
    "\n",
    "# # create_weights\n",
    "# weights = create_weights(number_bandwidths, \"uniform\") / number_kernels\n",
    "# # 展开成和 mmd_values 一样长（每个核都重复同一组带宽权重）\n",
    "# weights = jnp.tile(weights, number_kernels)\n",
    "\n",
    "# # 3. 加权聚合\n",
    "# mmd_loss = jnp.sum(weights * mmd_values)\n",
    "# print(\"Aggregate MMD (weighted sum over all kernels and bandwidths):\", float(mmd_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16454a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished step  100\n",
      "Finished step  200\n",
      "Finished step  300\n",
      "Finished step  400\n",
      "Finished step  500\n",
      "Finished step  600\n",
      "Finished step  700\n",
      "Finished step  800\n",
      "Finished step  900\n",
      "Finished step 1000\n",
      "saved -> params_20250716_165241.npy\n"
     ]
    }
   ],
   "source": [
    "import jax, jax.numpy as jnp, optax\n",
    "\n",
    "# ---------- 0) 假设已有 model.loss ----------\n",
    "def dummy_loss(p):      # 用自己的 model.loss 替换\n",
    "    return jnp.sum(p**2)\n",
    "\n",
    "# ---------- 1) 单步 update（JIT） ----------\n",
    "opt = optax.adam(1e-2)\n",
    "\n",
    "@jax.jit\n",
    "def update_step(params, opt_state):\n",
    "    loss_val, grads = jax.value_and_grad(dummy_loss)(params)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss_val\n",
    "\n",
    "# ---------- 2) 批量 k 步（scan 封装，k 静态） ----------\n",
    "def k_steps(params, opt_state, k):\n",
    "    def body(carry, _):\n",
    "        p, s = carry\n",
    "        p, s, _ = update_step(p, s)\n",
    "        return (p, s), None\n",
    "    (params, opt_state), _ = jax.lax.scan(body, (params, opt_state), None, length=k)\n",
    "    return params, opt_state\n",
    "\n",
    "k_steps = jax.jit(k_steps, static_argnums=2)\n",
    "\n",
    "# ---------- 3) 高层训练循环 ----------\n",
    "def train(params, n_steps=1000, block=100):\n",
    "    opt_state = opt.init(params)\n",
    "    for i in range(0, n_steps, block):\n",
    "        params, opt_state = k_steps(params, opt_state, block)\n",
    "        print(f\"Finished step {i+block:4d}\")\n",
    "    return params\n",
    "\n",
    "# ---------- 4) 试跑 ----------\n",
    "key = jax.random.PRNGKey(0)\n",
    "init_params = jax.random.normal(key, (50,), dtype=jnp.float32)\n",
    "trained_params = train(init_params, n_steps=1000, block=100)\n",
    "\n",
    "# 保存\n",
    "import numpy as np, pathlib, datetime as dt\n",
    "fname = f\"params_{dt.datetime.now():%Y%m%d_%H%M%S}.npy\"\n",
    "np.save(fname, jax.device_get(trained_params))\n",
    "print(\"saved ->\", fname)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
